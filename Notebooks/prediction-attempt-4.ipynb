{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/boston-crime-data/crime.csv', encoding='latin-1')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna(subset = ['Lat', 'Long'])\ndf = df[df['Lat'] > 0]\n\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna(subset=['UCR_PART'])\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['OFFENSE_CODE_GROUP'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"important= ['Aggravated Assault', \n      'Harassment', \n       'Arson', \n       'Homicide', \n       'Criminal Harassment', \n       'Biological Threat',\n       'Manslaughter', 'HUMAN TRAFFICKING',\n        'Auto Theft', 'Larceny','Robbery','Residential Burglary','Larcency From Motor Vehicle','Other Burglary','Commercial Burglary'\n   ]\n\n# 'Aggravated Assault', \n#       'Harassment', \n#        'Arson', \n#        'Homicide', \n#        'Criminal Harassment', \n#        'Biological Threat',\n#        'Manslaughter', 'HUMAN TRAFFICKING',\n#         'Auto Theft', 'Larceny','Robbery','Residential Burglary','Larcency From Motor Vehicle','Other Burglary','Commercial Burglary']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['important']=0\ni=0\nfor x in df['OFFENSE_CODE_GROUP']:\n      if x in important:\n        df['important'].iloc[i]=1\n    \n      i+=1\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df['important']==1]['OFFENSE_CODE_GROUP'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['DAY_OF_WEEK'] = df['DAY_OF_WEEK'].map({\n    'Tuesday':4, \n    'Saturday':2, \n    'Monday':3, \n    'Sunday':1, \n    'Thursday':5, \n    'Wednesday':6,\n    'Friday':7\n})\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndf['REPORTING_AREA'] = encoder.fit_transform(df['REPORTING_AREA'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dummies(dataframe):\n    \n#     for DISTRICT column\n    \n    DISTRICT = pd.get_dummies(dataframe.DISTRICT, prefix = 'DIS')\n    dataframe = pd.concat([dataframe,DISTRICT],axis = 1)\n    dataframe = dataframe.drop(['DISTRICT'],axis = 1)\n    \n    #for UCR PART column\n    \n    UCR_PART = pd.get_dummies(dataframe.UCR_PART, prefix = 'UCR')\n    dataframe = pd.concat([dataframe,UCR_PART],axis = 1)\n    dataframe = dataframe.drop(['UCR_PART'],axis = 1)\n    \n    return dataframe\ndf =get_dummies(df)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"OCCURRED_ON_DATE\"]=pd.to_datetime(df[\"OCCURRED_ON_DATE\"],infer_datetime_format=True)\ndf[\"OCCURRED_DAY\"]=df[\"OCCURRED_ON_DATE\"].apply(lambda x: x.date())\ndf = df.drop(['OCCURRED_ON_DATE'],axis = 1)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2016 = df[df[\"YEAR\"].isin([2016])]\ndf_2016","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_set2=df_2016.sample(30000)\nvalidation_set2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_set2[validation_set2['important']==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_set2 = validation_set2[['REPORTING_AREA','MONTH','HOUR','DAY_OF_WEEK','DIS_A1','DIS_A15',\n                'DIS_A7','DIS_B2','DIS_B3', 'DIS_C11', 'DIS_C6', 'DIS_D14', 'DIS_D4', 'DIS_E13', 'DIS_E18', 'DIS_E5','important']]\nvalidation_set2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groundTruth2 = validation_set2['important']\nvalidation_set2 = validation_set2.drop('important', axis=1)\nvalidation_set2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nvalidation_set2_scaled = scaler.fit_transform(validation_set2)\nvalidation_set2_scaled = pd.DataFrame(data=validation_set2_scaled, columns=['REPORTING_AREA','MONTH','HOUR','DAY_OF_WEEK','DIS_A1','DIS_A15',\n                'DIS_A7','DIS_B2','DIS_B3', 'DIS_C11', 'DIS_C6', 'DIS_D14', 'DIS_D4', 'DIS_E13', 'DIS_E18', 'DIS_E5'])\n\nvalidation_set2_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df[df[\"YEAR\"].isin([2017,2018])]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.important==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import resample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_majority = df[df.important==0]\ndf_minority = df[df.important==1]\n \n# Upsample minority class\ndf_majority_downsampled  = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=135498,    # to match majority class\n                                 random_state=123) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_majority_downsampled])\n \n# Display new class counts\ndf_upsampled.important.value_counts()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_upsampled = df_upsampled.sort_values(by =['OCCURRED_DAY'], ascending=False)\ndf_upsampled['OCCURRED_DAY']= pd.to_datetime(df_upsampled['OCCURRED_DAY'])\ndf_upsampled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\ndf_upsampled = shuffle(df_upsampled)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_upsampled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = df_upsampled[['REPORTING_AREA','MONTH','HOUR','DAY_OF_WEEK','DIS_A1','DIS_A15',\n                'DIS_A7','DIS_B2','DIS_B3', 'DIS_C11', 'DIS_C6', 'DIS_D14', 'DIS_D4', 'DIS_E13', 'DIS_E18', 'DIS_E5','important']].head((int(len(df_upsampled) *0.7)))\ntrain_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_set = df_upsampled[['REPORTING_AREA','MONTH','HOUR','DAY_OF_WEEK','DIS_A1','DIS_A15',\n                'DIS_A7','DIS_B2','DIS_B3', 'DIS_C11', 'DIS_C6', 'DIS_D14', 'DIS_D4', 'DIS_E13', 'DIS_E18', 'DIS_E5','important']].tail(int(len(df_upsampled) *0.3))\nvalidation_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = StandardScaler()\ntrain_scaled = scaler.fit_transform(train_set)\ntrain_scaled = pd.DataFrame(data=train_scaled, columns=['REPORTING_AREA','MONTH','HOUR','DAY_OF_WEEK','DIS_A1','DIS_A15',\n                'DIS_A7','DIS_B2','DIS_B3', 'DIS_C11', 'DIS_C6', 'DIS_D14', 'DIS_D4', 'DIS_E13', 'DIS_E18', 'DIS_E5','important'])\n\ntrain_scaled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groundTruth= validation_set['important'].to_frame()\n\ngroundTruth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaled_validation_set = scaler.fit_transform(validation_set)\nscaled_validation_set = pd.DataFrame(data=scaled_validation_set, columns=['REPORTING_AREA','MONTH','HOUR', 'DAY_OF_WEEK', 'DIS_A1','DIS_A15',\n                'DIS_A7','DIS_B2','DIS_B3', 'DIS_C11', 'DIS_C6', 'DIS_D14', 'DIS_D4', 'DIS_E13', 'DIS_E18', 'DIS_E5','important'])\nscaled_validation_set = scaled_validation_set.drop('important', axis=1)\nscaled_validation_set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.semi_supervised import LabelSpreading\nfrom sklearn.svm import LinearSVC\nfrom sklearn.neighbors.nearest_centroid import NearestCentroid\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n\ndef classification_metrics(y_test, predict):\n    print(\"Confusion Matrix:\\n\")\n    print(confusion_matrix(y_test, predict))\n    print(\"\\nAccuracy: \", accuracy_score(y_test, predict))\n    print(\"\\nClassification report:\\n\")\n    print(classification_report(y_test, predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(train_scaled.drop(columns=[\"important\"]), train_set[\"important\"], random_state = 0, test_size = 0.33, shuffle=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nxgB = XGBClassifier(learning_rate =0.1, n_estimators=1000,\n    max_depth=10, min_child_weight=5, subsample=0.8,colsample_bytree=0.8,\n    objective= 'binary:logistic',random_state=0)\nxgB.fit(x_train, y_train)\nxgb_test_predict = pd.DataFrame(data=xgB.predict(x_test))\nclassification_metrics(y_test, xgb_test_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_valid_predict = pd.DataFrame(data=xgB.predict(scaled_validation_set))\nxgB_accuracy = classification_metrics(groundTruth, xgb_valid_predict)\nprint('xgB_accuracy:', xgB_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_valid2_predict = pd.DataFrame(data=xgB.predict(validation_set2_scaled))\nxgB_accuracy = classification_metrics(groundTruth2, xgb_valid2_predict)\nprint('xgB_accuracy:', xgB_accuracy)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm = LGBMClassifier(random_state=0)\nlgbm.fit(x_train, y_train)\nlgbm_pred = lgbm.predict(x_test)\n\nclassification_metrics(y_test, lgbm_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_lgbm = pd.DataFrame(data=lgbm.predict(scaled_validation_set))\nlgbm_accuracy = classification_metrics(groundTruth, predict_lgbm)\nprint('lgbm_accuracy:', lgbm_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_lgbm2 = pd.DataFrame(data=lgbm.predict(validation_set2_scaled))\nlgbm_accuracy = classification_metrics(groundTruth2, predict_lgbm2)\nprint('lgbm_accuracy:', lgbm_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gauss = GaussianNB()\ngauss = gauss.fit(x_train, y_train)\ngauss_pred = gauss.predict(x_test)\n\nclassification_metrics(y_test, gauss_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data=gauss.predict(scaled_validation_set))\ngauss_accuracy = classification_metrics(groundTruth, predict)\n    \nprint('gauss_accuracy:', gauss_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict2 = pd.DataFrame(data=gauss.predict(validation_set2_scaled))\ngauss_accuracy = classification_metrics(groundTruth2, predict2)\n    \nprint('gauss_accuracy:', gauss_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbC = GradientBoostingClassifier(random_state=0, n_estimators=10)\ngbC.fit(x_train, y_train)\npredict = pd.DataFrame(data=gbC.predict(x_test), index = x_test.index)\nclassification_metrics(y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data=gbC.predict(scaled_validation_set))\ngbC_accuracy = classification_metrics(groundTruth, predict)\nprint('gbC_accuracy:', gbC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict2 = pd.DataFrame(data=gbC.predict(validation_set2_scaled))\ngbC_accuracy = classification_metrics(groundTruth2, predict2)\nprint('gbC_accuracy:', gbC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\n\nabC = AdaBoostClassifier(random_state=0, n_estimators=10, learning_rate=0.9)\nabC.fit(x_train, y_train)\npredict = pd.DataFrame(data=abC.predict(x_test), index = x_test.index)\nclassification_metrics(y_test, predict)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data=abC.predict(scaled_validation_set))\nabC_accuracy = classification_metrics(groundTruth, predict)\nprint('abC_accuracy:', abC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict2 = pd.DataFrame(data=abC.predict(validation_set2_scaled))\nabC_accuracy = classification_metrics(groundTruth2, predict2)\nprint('abC_accuracy:', abC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import ExtraTreesClassifier\netC = ExtraTreesClassifier(random_state=0, n_estimators=50)\n\netC.fit(x_train, y_train)\npredict = pd.DataFrame(data=etC.predict(x_test))\nclassification_metrics(y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data=etC.predict(scaled_validation_set))\netC_accuracy = classification_metrics(groundTruth, predict)\nprint('etC_accuracy:', etC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict2 = pd.DataFrame(data=etC.predict(validation_set2_scaled))\netC_accuracy = classification_metrics(groundTruth2, predict2)\nprint('etC_accuracy:', etC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrfC = RandomForestClassifier(criterion='entropy', max_depth= 8, max_leaf_nodes=5, min_samples_leaf=5, n_estimators= 100, random_state=0, class_weight='balanced_subsample')\n\nrfC.fit(x_train, y_train)\npredict = pd.DataFrame(data=rfC.predict(x_test))\nclassification_metrics(y_test, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = pd.DataFrame(data=rfC.predict(scaled_validation_set))\nrfC_accuracy = classification_metrics(groundTruth, predict)\nprint('rfC_accuracy:', rfC_accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict2 = pd.DataFrame(data=rfC.predict(validation_set2_scaled))\nrfC_accuracy = classification_metrics(groundTruth2, predict2)\nprint('rfC_accuracy:', rfC_accuracy)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}